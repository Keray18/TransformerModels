{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c93f356-a4ab-4a91-b692-b8b24c696611",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X:\\AI\\TextSummarizer(Transformers)\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import nltk\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12488505-c493-407d-ac55-376a7ceeab3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f465c770-0852-40c2-be13-5d3e51a3b58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3421b840-b7a5-4e6a-a21a-fc7eb0efe900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>\n",
       "      <td>By . Associated Press . PUBLISHED: . 14:11 EST...</td>\n",
       "      <td>Bishop John Folda, of North Dakota, is taking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>\n",
       "      <td>(CNN) -- Ralph Mata was an internal affairs li...</td>\n",
       "      <td>Criminal complaint: Cop used his role to help ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00027e965c8264c35cc1bc55556db388da82b07f</td>\n",
       "      <td>A drunk driver who killed a young woman in a h...</td>\n",
       "      <td>Craig Eccleston-Todd, 27, had drunk at least t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002c17436637c4fe1837c935c04de47adb18e9a</td>\n",
       "      <td>(CNN) -- With a breezy sweep of his pen Presid...</td>\n",
       "      <td>Nina dos Santos says Europe must be ready to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0003ad6ef0c37534f80b55b4235108024b407f0b</td>\n",
       "      <td>Fleetwood are the only team still to have a 10...</td>\n",
       "      <td>Fleetwood top of League One after 2-0 win at S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0  0001d1afc246a7964130f43ae940af6bc6c57f01   \n",
       "1  0002095e55fcbd3a2f366d9bf92a95433dc305ef   \n",
       "2  00027e965c8264c35cc1bc55556db388da82b07f   \n",
       "3  0002c17436637c4fe1837c935c04de47adb18e9a   \n",
       "4  0003ad6ef0c37534f80b55b4235108024b407f0b   \n",
       "\n",
       "                                             article  \\\n",
       "0  By . Associated Press . PUBLISHED: . 14:11 EST...   \n",
       "1  (CNN) -- Ralph Mata was an internal affairs li...   \n",
       "2  A drunk driver who killed a young woman in a h...   \n",
       "3  (CNN) -- With a breezy sweep of his pen Presid...   \n",
       "4  Fleetwood are the only team still to have a 10...   \n",
       "\n",
       "                                          highlights  \n",
       "0  Bishop John Folda, of North Dakota, is taking ...  \n",
       "1  Criminal complaint: Cop used his role to help ...  \n",
       "2  Craig Eccleston-Todd, 27, had drunk at least t...  \n",
       "3  Nina dos Santos says Europe must be ready to a...  \n",
       "4  Fleetwood top of League One after 2-0 win at S...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = pd.read_csv(\"../Dataset/train.csv\")\n",
    "train_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "256519e0-348b-43c5-9dc8-baf54205c77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287113"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "275d365e-fb20-4376-aae5-323c1268714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = train_ds.sample(n=500, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f36fd0d1-e294-48dc-90f6-a452e96c80d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(sampled_df, test_size=0.2, random_state=42)\n",
    "\n",
    "len(train_df), len(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7ebacc5-999e-44a4-ac87-1da926370e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df[['article', 'highlights']]) \n",
    "val_dataset = Dataset.from_pandas(val_df[['article', 'highlights']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9291918d-6c20-40ee-99a2-c8eb64756916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(dataset):\n",
    "    inputs = tokenizer(dataset['article'],\n",
    "                      max_length=1024,\n",
    "                      truncation=True,\n",
    "                      padding=\"max_length\",\n",
    "                      return_tensors=\"pt\")\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        outputs = tokenizer(\n",
    "            dataset['highlights'],\n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "    model_inputs = {\n",
    "        'input_ids' : inputs['input_ids'],\n",
    "        'attention_mask': inputs['attention_mask'],\n",
    "        'labels': outputs['input_ids']\n",
    "    }\n",
    "\n",
    "    labels = model_inputs['labels'].clone()\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    model_inputs['labels'] = labels\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eda83b3d-b2a5-47ff-bbb6-b63947d06f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    predictions, labels = eval_preds\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge_scores = {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n",
    "\n",
    "    for pred, label in zip(decoded_preds, decoded_labels):\n",
    "        scores = scorer.score(label, pred)\n",
    "        rouge_scores['rouge1'] += scores['rouge1'].fmeasure\n",
    "        rouge_scores['rouge2'] += scores['rouge2'].fmeasure\n",
    "        rouge_scores['rougeL'] += scores['rougeL'].fmeasure\n",
    "\n",
    "    num_samples = len(decoded_preds)\n",
    "    for key in rouge_scores:\n",
    "        rouge_scores[key] = rouge_scores[key] / num_samples\n",
    "    \n",
    "    return rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "445866d7-8021-4be0-8258-b45be2b69cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded: facebook/bart-large-cnn\n"
     ]
    }
   ],
   "source": [
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "print(f\"Model Loaded: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2e5567e-cb17-46dc-9b70-9b6b768b1ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|                                                                              | 0/400 [00:00<?, ? examples/s]X:\\AI\\TextSummarizer(Transformers)\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████| 400/400 [00:02<00:00, 152.19 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 145.99 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: Dataset({\n",
      "    features: ['article', 'highlights', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 400\n",
      "})\n",
      "training: Dataset({\n",
      "    features: ['article', 'highlights', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 400\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_df = train_dataset.map(preprocessing, batched=True, batch_size=8)\n",
    "tokenized_val_df = val_dataset.map(preprocessing, batched=True, batch_size=8)\n",
    "\n",
    "print(f\"training: {tokenized_train_df}\")\n",
    "print(f\"training: {tokenized_train_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48fa0768-2988-4670-8c50-4d288f6ca73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93ea39bd-f43e-477e-a645-b365f70f8d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesha\\AppData\\Local\\Temp\\ipykernel_14772\\3144851106.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 2:22:38, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.261993</td>\n",
       "      <td>0.414907</td>\n",
       "      <td>0.196623</td>\n",
       "      <td>0.278230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.141600</td>\n",
       "      <td>1.283670</td>\n",
       "      <td>0.422065</td>\n",
       "      <td>0.206281</td>\n",
       "      <td>0.296459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.141600</td>\n",
       "      <td>1.370357</td>\n",
       "      <td>0.426575</td>\n",
       "      <td>0.203540</td>\n",
       "      <td>0.287945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X:\\AI\\TextSummarizer(Transformers)\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:3353: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=128,\n",
    "    generation_num_beams=4,\n",
    "    fp16=True,  \n",
    "    logging_steps=100,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"rouge1\",\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_df,\n",
    "    eval_dataset=tokenized_val_df,\n",
    "    # tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebf7317d-f3d7-482d-a0ba-e542b09971ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(article, max_length=150, min_length=40, num_beams=4):\n",
    "    inputs = tokenizer(\n",
    "        article,\n",
    "        max_length=1024,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    summary_ids = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_length=max_length,\n",
    "        min_length=min_length,\n",
    "        num_beams=num_beams,\n",
    "        length_penalty=2.0,\n",
    "        early_stopping=True,\n",
    "        no_repeat_ngram_size=3,  \n",
    "        repetition_penalty=1.5,  \n",
    "    )\n",
    "\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "175f01f4-4091-4b7c-8af7-e1bb431807f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article='''ronda rousey recorded fastest-ever finish ufc title fight submitted cat zingano second los angeles', 'rousey expected face toughest examination reign bantamweight champion unbeaten zingano', 'avoided flying knee opening second rousey took opponent set work trying execute trademark armbar', 'scroll watch rousey beat zingano second', 'ronda rousey manoeuvre position submit cat zingano second fight', 'rousey attempt lock trademark arm bar finish defended bantamweight title', 'rousey console zingano stunning victory inside second staple center los angeles', 'rousey grapple zingano celebrating octagon record-breaking victory', 'ronda rousey bt cat zingano via sub', 'holly holm bt raquel pennington via sd', 'jake ellenberger bt josh koscheck via sub', 'alan jouban bt richard walsh via ko', 'tony ferguson bt gleison tibau via sub', 'roan carneiro bt mark munoz via sub', 'roman salazar bt norifumi yamamoto n/c', 'tim mean bt dhiego lima via tko', 'derrick lewis bt ruan potts via tko', 'valmir lazaro bt james krause via sd', 'masio fullen bt alexander torres via sd', \"rousey landed head champion gracefully flipped zingano back got manoeuvred swiftly position wrench zingano 's arm grotesquely\", 'rousey forced challenger tap', \"'we expecting might come something flying right away rousey said\", \"'that 's usually land armbar angle work\", 'lot like judo transition scramble second hit ground', 'made fly honest', \"kind funny going toward ground kind reverted back judo mode thinking 'do n't touch back\", \"'s point\", \"'that 's acrobatic thing came thinking touching back judo\", 'hard work stunned zingano sell-out staple center', \"'she 's really good ... would n't happen beaten challenger said\", \"'it knee throw scramble wrapped around arm\", 'got caught', 'ready million different thing', 'planned getting fist fight tonight', 'zingano look pain rousey move position execute armbar finish', 'rousey mixed martial art fight one inside first round', 'rousey celebrates zingano attended referee following early defeat los angeles', 'dublin featherweight conor mcgregor left light-heavyweight champion jon jones attendance', 'former ufc heavyweight champion brock lesnar octagon side rousey eased victory', \"first time promotion 's history two woman 's fight headlined pay-per-view event boxer holly holm made debut split-decision victory raquel pennington co-main event\", 'middleweight champion chris weidman originally scheduled fight vitor belfort withdraw injured', \"zingano earned title shot two year ago upset victory miesha tate forced wait suffering serious knee injury hit estranged husband 's suicide last year\", 'holm meanwhile ended pro boxing career concentrate mma two year ago looked far complete package pennington', 'fighter landed big shot stand-up fight holm finished bloody nose left pennington swollen left eye', 'ufc octagon girl vanessa hanson brittney palmer arianny celeste chrissy blair pose picture', 'vanessa brittney introduce first round respective fight ufc los angeles', 'holly holm right made winning debut split-decision victory raquel pennington', 'holm moved boxing career mixed martial art remains unbeaten', 'pennington land left hand holm battled hard lose split decision', 'actress mandy moore left minka kelly pose photograph ufc event', 'vin diesel also staple center left ufc president dana white pose mark wahlberg'''\n",
    "\n",
    "summary = generate_summary(test_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95cbaaff-351b-4aaa-b6ab-25d5476d2f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ronda rousey recorded fastest-ever finish ufc title fight submitted cat zingano second los angeles .\\n\\'Zingano stunning victory inside second staple center\\'\\n\\'Rousey\\xa0described\\xa0her armbar technique as \\'lot like judo transition scramble second hit ground\\'\\n\"Holly holm made winning debut split-decision victory raquel pennington co-main event .'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b89fc4b9-a4dc-4b75-a57c-7a7ba6c057e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to Model&Preprocessor\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"Model&Preprocessor/textSummarizerModel\")\n",
    "tokenizer.save_pretrained(\"Model&Preprocessor/textSummarizerTokenizer\")\n",
    "print(\"Model saved to Model&Preprocessor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd49408-c6f1-456e-9406-5844b82ee52b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
